{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819be38a-921a-485a-8e1f-58daeadc14ac",
   "metadata": {},
   "source": [
    "# Using pytest in a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55984bca-1e25-45f9-8c31-ce080b2cdcfb",
   "metadata": {},
   "source": [
    "Here is a function we are prototyping in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c489c7-9c94-43ee-9696-a4e56681fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_angry_text(input_string: str) -> bool:\n",
    "    upper_case_count = sum(1 for c in input_string if c.isupper())\n",
    "    anger_threshold = 0.5\n",
    "    return upper_case_count / len(input_string) > anger_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a631bf8",
   "metadata": {},
   "source": [
    "We would probably check it does what we want by calling it with a couple of examples, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2913ab6-3ae7-40ae-84ef-258bc757676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_angry_text(\"hello\") is False\n",
    "assert is_angry_text(\"GO AWAY!\") is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e87dc-5e78-4b1c-b880-a948658b13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is very easy to go from doing this to creating and running a pytest test instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4130905",
   "metadata": {},
   "source": [
    "First we import ipytest (`pip install ipytest` if not installed) and configure it (this only needs to be done once in a notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7db93",
   "metadata": {},
   "source": [
    "Then in any cell where we define a pytest test (i.e. any function whose name begins with test that contains assertions), we can add the magic `%%ipytest` to execute it using pytest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f842ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "def test_is_angry_text() -> None:\n",
    "    assert is_angry_text(\"hello\") is False\n",
    "    assert is_angry_text(\"GO AWAY!\") is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320c72c",
   "metadata": {},
   "source": [
    "Now we get a nice pytest traceback in our notebook when a test fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "def test_is_angry_text_fail() -> None:\n",
    "    assert is_angry_text(\"hello\") is False\n",
    "    assert is_angry_text(\"GO AWAY!\") is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b23b2",
   "metadata": {},
   "source": [
    "And if one day we transfer this function to a python module or package we can then easily copy over our pytest tests as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
