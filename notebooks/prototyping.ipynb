{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using pytest in a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Here is a function we are prototyping in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_angry_text(input_string: str) -> bool:\n",
    "    upper_case_count = sum(1 for c in input_string if c.isupper())\n",
    "    anger_threshold = 0.5\n",
    "    return upper_case_count / len(input_string) > anger_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We would probably check it does what we want by calling it with a couple of examples, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_angry_text(\"hello\") is False\n",
    "assert is_angry_text(\"GO AWAY!\") is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "It is very easy to go from doing this to creating and running a pytest test instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "First we import ipytest (`pip install ipytest` if not installed) and configure it (this only needs to be done once in a notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Then in any cell where we define a pytest test (i.e. any function whose name begins with `test` that contains assertions), we can add the magic `%%ipytest` to execute it using pytest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "def test_is_angry_text() -> None:\n",
    "    assert is_angry_text(\"hello\") is False\n",
    "    assert is_angry_text(\"GO AWAY!\") is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now we get a nice pytest traceback in our notebook when a test fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "def test_is_angry_text_fail() -> None:\n",
    "    assert is_angry_text(\"hello\") is False\n",
    "    assert is_angry_text(\"GO AWAY!\") is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "And if one day we transfer this function to a python module or package we can then easily copy over our pytest tests as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
